{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa1aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e335d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9c416",
   "metadata": {},
   "source": [
    "# Intro to Neural Networks\n",
    "\n",
    "## Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282a4d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f57080",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.uniform(size = (200, 500))\n",
    "B = np.random.uniform(size = (500, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ab43f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200, 200), dtype=float64, numpy=\n",
       "array([[127.24522129, 123.09367397, 123.11675354, ..., 124.3268622 ,\n",
       "        128.86083907, 132.11287904],\n",
       "       [123.02809325, 123.52609522, 119.19766634, ..., 121.45162854,\n",
       "        121.98163823, 128.75521498],\n",
       "       [117.50754082, 116.60337139, 116.56676013, ..., 117.77602778,\n",
       "        117.28467566, 122.94939686],\n",
       "       ...,\n",
       "       [128.36805345, 127.71596173, 120.30973894, ..., 131.47537736,\n",
       "        128.81665996, 137.91502215],\n",
       "       [121.24690387, 120.99482829, 118.72616612, ..., 120.18345776,\n",
       "        124.99874792, 134.52654949],\n",
       "       [119.82505325, 121.95549942, 118.43563334, ..., 122.7094102 ,\n",
       "        121.61850346, 126.90456199]])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a545352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1156   49  784 2601  400]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "a = np.array([5, 1, 2, 3, 10])\n",
    "b = np.array([8, -3, 8, 15, 0])\n",
    "\n",
    "result = (2 * a + 3 * b) ** 2\n",
    "\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e19e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1156   49  784 2601  400], shape=(5,), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([5, 1, 2, 3, 10])\n",
    "b = tf.constant([8, -3, 8, 15, 0])\n",
    "\n",
    "result = (2 * a + 3 * b) ** 2\n",
    "\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "328e3a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bccd8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1156   49  784 2601  400], shape=(5,), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(np.array([5, 1, 2, 3, 10]))\n",
    "b = tf.constant(np.array([8, -3, 8, 15, 0]))\n",
    "\n",
    "result = (2 * a + 3 * b) ** 2\n",
    "\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b9701ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1156, shape=(), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(5)\n",
    "b = tf.constant(8)\n",
    "\n",
    "result = (2 * a + 3 * b) ** 2\n",
    "\n",
    "print(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2770013d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1156,   49,  784, 2601,  400])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(np.array([5, 1, 2, 3, 10]))\n",
    "b = tf.constant(np.array([8, -3, 8, 15, 0]))\n",
    "\n",
    "tf.pow(tf.add(tf.multiply(2, a), tf.multiply(3, b)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48fa3946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24d6f229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.4888455985020832>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(np.random.uniform(size = (10, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe3889b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f7161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = pd.read_csv(\"./data/adult.data\", sep = \", \", engine = \"python\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4199ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data.columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "759a0ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income_class  \n",
       "0              2174             0              40  United-States        <=50K  \n",
       "1                 0             0              13  United-States        <=50K  \n",
       "2                 0             0              40  United-States        <=50K  \n",
       "3                 0             0              40  United-States        <=50K  \n",
       "4                 0             0              40           Cuba        <=50K  \n",
       "...             ...           ...             ...            ...          ...  \n",
       "32556             0             0              38  United-States        <=50K  \n",
       "32557             0             0              40  United-States         >50K  \n",
       "32558             0             0              40  United-States        <=50K  \n",
       "32559             0             0              20  United-States        <=50K  \n",
       "32560         15024             0              40  United-States         >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cd61bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes, income_target = income_data.drop(columns = [\"income_class\"]), income_data.income_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1215bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes = pd.get_dummies(income_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76d67ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes = income_attributes.drop(columns = [\"fnlwgt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eddac20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_target = income_target.replace({\"<=50K\": 0, \">50K\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19bd989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_attributes_train, income_attributes_test, income_target_train, income_target_test = train_test_split(\n",
    "    income_attributes, income_target, stratify = income_target, test_size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee03d041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.759189\n",
       "1    0.240811\n",
       "Name: income_class, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_target_train.value_counts() / len(income_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd14582d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7592\n",
       "1    0.2408\n",
       "Name: income_class, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_target_test.value_counts() / len(income_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54a6fe56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Never-worked</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Portugal</th>\n",
       "      <th>native-country_Puerto-Rico</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29467</th>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19043</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21382</th>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24538</th>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14725</th>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>10605</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17832</th>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184</th>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27561 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "29467   30             13             0             0              45   \n",
       "19043   30             10             0             0              40   \n",
       "3478    35             13             0             0              40   \n",
       "21382   62             14             0             0              50   \n",
       "24538   32             13             0             0              30   \n",
       "...    ...            ...           ...           ...             ...   \n",
       "14725   65             13         10605             0              40   \n",
       "7757    50             10             0             0              60   \n",
       "8140    27              9             0             0              50   \n",
       "17832   66              4             0             0              20   \n",
       "4184    22             13             0             0              40   \n",
       "\n",
       "       workclass_?  workclass_Federal-gov  workclass_Local-gov  \\\n",
       "29467            0                      0                    0   \n",
       "19043            0                      0                    0   \n",
       "3478             0                      0                    0   \n",
       "21382            0                      0                    1   \n",
       "24538            0                      0                    0   \n",
       "...            ...                    ...                  ...   \n",
       "14725            1                      0                    0   \n",
       "7757             0                      0                    0   \n",
       "8140             0                      0                    0   \n",
       "17832            0                      0                    1   \n",
       "4184             0                      0                    0   \n",
       "\n",
       "       workclass_Never-worked  workclass_Private  ...  \\\n",
       "29467                       0                  1  ...   \n",
       "19043                       0                  1  ...   \n",
       "3478                        0                  1  ...   \n",
       "21382                       0                  0  ...   \n",
       "24538                       0                  1  ...   \n",
       "...                       ...                ...  ...   \n",
       "14725                       0                  0  ...   \n",
       "7757                        0                  1  ...   \n",
       "8140                        0                  1  ...   \n",
       "17832                       0                  0  ...   \n",
       "4184                        0                  1  ...   \n",
       "\n",
       "       native-country_Portugal  native-country_Puerto-Rico  \\\n",
       "29467                        0                           0   \n",
       "19043                        0                           0   \n",
       "3478                         0                           0   \n",
       "21382                        0                           0   \n",
       "24538                        0                           0   \n",
       "...                        ...                         ...   \n",
       "14725                        0                           0   \n",
       "7757                         0                           0   \n",
       "8140                         0                           0   \n",
       "17832                        0                           0   \n",
       "4184                         0                           0   \n",
       "\n",
       "       native-country_Scotland  native-country_South  native-country_Taiwan  \\\n",
       "29467                        0                     0                      0   \n",
       "19043                        0                     0                      0   \n",
       "3478                         0                     0                      0   \n",
       "21382                        0                     0                      0   \n",
       "24538                        0                     0                      0   \n",
       "...                        ...                   ...                    ...   \n",
       "14725                        0                     0                      0   \n",
       "7757                         0                     0                      0   \n",
       "8140                         0                     0                      0   \n",
       "17832                        0                     0                      0   \n",
       "4184                         0                     0                      0   \n",
       "\n",
       "       native-country_Thailand  native-country_Trinadad&Tobago  \\\n",
       "29467                        0                               0   \n",
       "19043                        0                               0   \n",
       "3478                         0                               0   \n",
       "21382                        0                               0   \n",
       "24538                        0                               0   \n",
       "...                        ...                             ...   \n",
       "14725                        0                               0   \n",
       "7757                         0                               0   \n",
       "8140                         0                               0   \n",
       "17832                        0                               0   \n",
       "4184                         0                               0   \n",
       "\n",
       "       native-country_United-States  native-country_Vietnam  \\\n",
       "29467                             1                       0   \n",
       "19043                             1                       0   \n",
       "3478                              1                       0   \n",
       "21382                             0                       0   \n",
       "24538                             1                       0   \n",
       "...                             ...                     ...   \n",
       "14725                             1                       0   \n",
       "7757                              1                       0   \n",
       "8140                              1                       0   \n",
       "17832                             1                       0   \n",
       "4184                              1                       0   \n",
       "\n",
       "       native-country_Yugoslavia  \n",
       "29467                          0  \n",
       "19043                          0  \n",
       "3478                           0  \n",
       "21382                          0  \n",
       "24538                          0  \n",
       "...                          ...  \n",
       "14725                          0  \n",
       "7757                           0  \n",
       "8140                           0  \n",
       "17832                          0  \n",
       "4184                           0  \n",
       "\n",
       "[27561 rows x 107 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_attributes_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7056107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaller = MinMaxScaler()\n",
    "income_attributes_train_scalled = scaller.fit_transform(income_attributes_train)\n",
    "income_attributes_test_scalled = scaller.transform(income_attributes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05a96372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_attributes_train_scalled.max(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fd54e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attrubutes = income_attributes.shape[1]\n",
    "num_attrubutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bafb3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = Sequential([\n",
    "    Input(shape = (num_attrubutes, )),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "], name = \"log_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3a13355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"log_reg\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 1)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108\n",
      "Trainable params: 108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logistic_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "934d444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression.compile(loss = \"binary_crossentropy\", optimizer = \"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6860d68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "862/862 [==============================] - 1s 636us/step - loss: 1501.7423\n",
      "Epoch 2/99\n",
      "862/862 [==============================] - 1s 618us/step - loss: 1435.8555\n",
      "Epoch 3/99\n",
      "862/862 [==============================] - 1s 635us/step - loss: 1393.4595\n",
      "Epoch 4/99\n",
      "862/862 [==============================] - 1s 601us/step - loss: 1376.4418\n",
      "Epoch 5/99\n",
      "862/862 [==============================] - 1s 622us/step - loss: 1505.4445\n",
      "Epoch 6/99\n",
      "862/862 [==============================] - 1s 617us/step - loss: 2223.0808\n",
      "Epoch 7/99\n",
      "862/862 [==============================] - 1s 630us/step - loss: 1410.2860\n",
      "Epoch 8/99\n",
      "862/862 [==============================] - 1s 659us/step - loss: 2122.3511\n",
      "Epoch 9/99\n",
      "862/862 [==============================] - 1s 631us/step - loss: 1373.9933\n",
      "Epoch 10/99\n",
      "862/862 [==============================] - 1s 635us/step - loss: 1343.0771\n",
      "Epoch 11/99\n",
      "862/862 [==============================] - 1s 625us/step - loss: 1287.6337\n",
      "Epoch 12/99\n",
      "862/862 [==============================] - 1s 623us/step - loss: 1368.2336\n",
      "Epoch 13/99\n",
      "862/862 [==============================] - 1s 624us/step - loss: 1094.2471\n",
      "Epoch 14/99\n",
      "862/862 [==============================] - 1s 622us/step - loss: 1713.5610\n",
      "Epoch 15/99\n",
      "862/862 [==============================] - 1s 606us/step - loss: 2045.8815\n",
      "Epoch 16/99\n",
      "862/862 [==============================] - 1s 648us/step - loss: 1149.5626\n",
      "Epoch 17/99\n",
      "862/862 [==============================] - 1s 645us/step - loss: 2014.1501\n",
      "Epoch 18/99\n",
      "862/862 [==============================] - 1s 656us/step - loss: 1290.4951\n",
      "Epoch 19/99\n",
      "862/862 [==============================] - 1s 626us/step - loss: 1711.5607\n",
      "Epoch 20/99\n",
      "862/862 [==============================] - 1s 645us/step - loss: 1443.2393\n",
      "Epoch 21/99\n",
      "862/862 [==============================] - 1s 644us/step - loss: 1391.4061\n",
      "Epoch 22/99\n",
      "862/862 [==============================] - 1s 609us/step - loss: 1546.5586\n",
      "Epoch 23/99\n",
      "862/862 [==============================] - 1s 664us/step - loss: 1258.2213\n",
      "Epoch 24/99\n",
      "862/862 [==============================] - 1s 628us/step - loss: 1523.1870\n",
      "Epoch 25/99\n",
      "862/862 [==============================] - 1s 635us/step - loss: 1447.8624\n",
      "Epoch 26/99\n",
      "862/862 [==============================] - 1s 627us/step - loss: 1343.8691\n",
      "Epoch 27/99\n",
      "862/862 [==============================] - 1s 625us/step - loss: 1353.8890\n",
      "Epoch 28/99\n",
      "862/862 [==============================] - 1s 633us/step - loss: 1721.0139\n",
      "Epoch 29/99\n",
      "862/862 [==============================] - 1s 611us/step - loss: 1649.2900\n",
      "Epoch 30/99\n",
      "862/862 [==============================] - 1s 624us/step - loss: 1429.1938\n",
      "Epoch 31/99\n",
      "862/862 [==============================] - 1s 621us/step - loss: 1563.9485\n",
      "Epoch 32/99\n",
      "862/862 [==============================] - 1s 618us/step - loss: 1921.6583\n",
      "Epoch 33/99\n",
      "862/862 [==============================] - 1s 620us/step - loss: 1808.7922\n",
      "Epoch 34/99\n",
      "862/862 [==============================] - 1s 605us/step - loss: 1608.4116\n",
      "Epoch 35/99\n",
      "862/862 [==============================] - 1s 628us/step - loss: 1257.1592\n",
      "Epoch 36/99\n",
      "862/862 [==============================] - 1s 633us/step - loss: 1334.6793\n",
      "Epoch 37/99\n",
      "862/862 [==============================] - 1s 627us/step - loss: 1588.5586\n",
      "Epoch 38/99\n",
      "862/862 [==============================] - 1s 600us/step - loss: 1706.3943\n",
      "Epoch 39/99\n",
      "862/862 [==============================] - 1s 632us/step - loss: 1564.7706\n",
      "Epoch 40/99\n",
      "862/862 [==============================] - 1s 631us/step - loss: 1274.2094\n",
      "Epoch 41/99\n",
      "862/862 [==============================] - 1s 613us/step - loss: 1355.6960\n",
      "Epoch 42/99\n",
      "862/862 [==============================] - 1s 614us/step - loss: 1485.4944\n",
      "Epoch 43/99\n",
      "862/862 [==============================] - 1s 626us/step - loss: 1453.3976\n",
      "Epoch 44/99\n",
      "862/862 [==============================] - 1s 612us/step - loss: 1267.6182\n",
      "Epoch 45/99\n",
      "862/862 [==============================] - 1s 624us/step - loss: 1439.0367\n",
      "Epoch 46/99\n",
      "862/862 [==============================] - 1s 618us/step - loss: 1282.3024\n",
      "Epoch 47/99\n",
      "862/862 [==============================] - 1s 626us/step - loss: 1561.0687\n",
      "Epoch 48/99\n",
      "862/862 [==============================] - 1s 624us/step - loss: 1448.2844\n",
      "Epoch 49/99\n",
      "862/862 [==============================] - 1s 619us/step - loss: 1381.4823\n",
      "Epoch 50/99\n",
      "862/862 [==============================] - 1s 623us/step - loss: 1273.0554\n",
      "Epoch 51/99\n",
      "862/862 [==============================] - 1s 626us/step - loss: 1415.6458\n",
      "Epoch 52/99\n",
      "862/862 [==============================] - 1s 631us/step - loss: 1730.0780\n",
      "Epoch 53/99\n",
      "862/862 [==============================] - 1s 605us/step - loss: 1642.2885\n",
      "Epoch 54/99\n",
      "862/862 [==============================] - 1s 621us/step - loss: 2329.5820\n",
      "Epoch 55/99\n",
      "862/862 [==============================] - 1s 632us/step - loss: 1537.8177\n",
      "Epoch 56/99\n",
      "862/862 [==============================] - 1s 616us/step - loss: 1736.9442\n",
      "Epoch 57/99\n",
      "862/862 [==============================] - 1s 613us/step - loss: 1844.5499\n",
      "Epoch 58/99\n",
      "862/862 [==============================] - 1s 620us/step - loss: 1831.0197\n",
      "Epoch 59/99\n",
      "862/862 [==============================] - 1s 622us/step - loss: 1362.0833\n",
      "Epoch 60/99\n",
      "862/862 [==============================] - 1s 612us/step - loss: 1621.6027\n",
      "Epoch 61/99\n",
      "862/862 [==============================] - 1s 620us/step - loss: 1866.6183\n",
      "Epoch 62/99\n",
      "862/862 [==============================] - 1s 623us/step - loss: 1432.2836\n",
      "Epoch 63/99\n",
      "862/862 [==============================] - 1s 626us/step - loss: 1412.0455\n",
      "Epoch 64/99\n",
      "862/862 [==============================] - 1s 636us/step - loss: 1666.6686\n",
      "Epoch 65/99\n",
      "862/862 [==============================] - 1s 656us/step - loss: 1492.9366\n",
      "Epoch 66/99\n",
      "862/862 [==============================] - 1s 636us/step - loss: 1928.1248\n",
      "Epoch 67/99\n",
      "862/862 [==============================] - 1s 644us/step - loss: 1837.7063\n",
      "Epoch 68/99\n",
      "862/862 [==============================] - 1s 610us/step - loss: 1563.7179\n",
      "Epoch 69/99\n",
      "862/862 [==============================] - 1s 622us/step - loss: 1529.9911\n",
      "Epoch 70/99\n",
      "862/862 [==============================] - 1s 646us/step - loss: 1361.8618\n",
      "Epoch 71/99\n",
      "862/862 [==============================] - 1s 622us/step - loss: 1729.5934\n",
      "Epoch 72/99\n",
      "862/862 [==============================] - 1s 641us/step - loss: 1352.2015\n",
      "Epoch 73/99\n",
      "862/862 [==============================] - 1s 615us/step - loss: 1819.0123\n",
      "Epoch 74/99\n",
      "862/862 [==============================] - 1s 619us/step - loss: 1237.7831\n",
      "Epoch 75/99\n",
      "862/862 [==============================] - 1s 619us/step - loss: 1772.0629\n",
      "Epoch 76/99\n",
      "862/862 [==============================] - 1s 614us/step - loss: 1792.7675\n",
      "Epoch 77/99\n",
      "862/862 [==============================] - 1s 620us/step - loss: 1284.5261\n",
      "Epoch 78/99\n",
      "862/862 [==============================] - 1s 619us/step - loss: 1434.8472\n",
      "Epoch 79/99\n",
      "862/862 [==============================] - 1s 628us/step - loss: 1954.4822\n",
      "Epoch 80/99\n",
      "862/862 [==============================] - 1s 624us/step - loss: 1759.3137\n",
      "Epoch 81/99\n",
      "862/862 [==============================] - 1s 612us/step - loss: 1375.9636\n",
      "Epoch 82/99\n",
      "862/862 [==============================] - 1s 630us/step - loss: 1623.8893\n",
      "Epoch 83/99\n",
      "862/862 [==============================] - 1s 606us/step - loss: 1260.5956\n",
      "Epoch 84/99\n",
      "862/862 [==============================] - 1s 628us/step - loss: 1590.4043\n",
      "Epoch 85/99\n",
      "862/862 [==============================] - 1s 605us/step - loss: 1867.6505\n",
      "Epoch 86/99\n",
      "862/862 [==============================] - 1s 607us/step - loss: 1514.9319\n",
      "Epoch 87/99\n",
      "862/862 [==============================] - 1s 648us/step - loss: 1303.3519\n",
      "Epoch 88/99\n",
      "862/862 [==============================] - 1s 628us/step - loss: 1515.0775\n",
      "Epoch 89/99\n",
      "862/862 [==============================] - 1s 621us/step - loss: 1594.1566\n",
      "Epoch 90/99\n",
      "862/862 [==============================] - 1s 611us/step - loss: 2004.5023\n",
      "Epoch 91/99\n",
      "862/862 [==============================] - 1s 630us/step - loss: 1525.9391\n",
      "Epoch 92/99\n",
      "862/862 [==============================] - 1s 623us/step - loss: 1555.4906\n",
      "Epoch 93/99\n",
      "862/862 [==============================] - 1s 655us/step - loss: 1629.9579\n",
      "Epoch 94/99\n",
      "862/862 [==============================] - 1s 638us/step - loss: 1775.0190\n",
      "Epoch 95/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 1s 637us/step - loss: 1900.9220\n",
      "Epoch 96/99\n",
      "862/862 [==============================] - 1s 618us/step - loss: 1495.5946\n",
      "Epoch 97/99\n",
      "862/862 [==============================] - 1s 646us/step - loss: 1499.2208\n",
      "Epoch 98/99\n",
      "862/862 [==============================] - 1s 628us/step - loss: 1503.5367\n",
      "Epoch 99/99\n",
      "862/862 [==============================] - 1s 640us/step - loss: 1365.6696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1797360c550>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(income_attributes_train, income_target_train, epochs = 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5631c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential([\n",
    "    Input(shape = (num_attrubutes, )),\n",
    "    \n",
    "    Dense(30, activation = \"relu\"),\n",
    "    Dense(20, activation = \"relu\"),\n",
    "    Dense(10, activation = \"relu\"),\n",
    "    \n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "], name = \"nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc123edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_41 (Dense)            (None, 30)                3240      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 20)                620       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,081\n",
      "Trainable params: 4,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69867637",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss = \"binary_crossentropy\", optimizer = \"sgd\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6318d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/99\n",
      "862/862 [==============================] - 1s 812us/step - loss: 1.4925 - accuracy: 0.7577\n",
      "Epoch 2/99\n",
      "862/862 [==============================] - 1s 825us/step - loss: 0.5079 - accuracy: 0.7592\n",
      "Epoch 3/99\n",
      "862/862 [==============================] - 1s 805us/step - loss: 0.4938 - accuracy: 0.7592\n",
      "Epoch 4/99\n",
      "862/862 [==============================] - 1s 800us/step - loss: 0.4807 - accuracy: 0.7592\n",
      "Epoch 5/99\n",
      "862/862 [==============================] - 1s 888us/step - loss: 0.4673 - accuracy: 0.7592\n",
      "Epoch 6/99\n",
      "862/862 [==============================] - 1s 872us/step - loss: 0.4550 - accuracy: 0.7592\n",
      "Epoch 7/99\n",
      "862/862 [==============================] - 1s 868us/step - loss: 0.4432 - accuracy: 0.7592\n",
      "Epoch 8/99\n",
      "862/862 [==============================] - 1s 871us/step - loss: 0.4457 - accuracy: 0.7592\n",
      "Epoch 9/99\n",
      "862/862 [==============================] - 1s 900us/step - loss: 0.4288 - accuracy: 0.7605\n",
      "Epoch 10/99\n",
      "862/862 [==============================] - 1s 908us/step - loss: 0.4286 - accuracy: 0.7602\n",
      "Epoch 11/99\n",
      "862/862 [==============================] - 1s 803us/step - loss: 0.4228 - accuracy: 0.7795\n",
      "Epoch 12/99\n",
      "862/862 [==============================] - 1s 799us/step - loss: 0.4214 - accuracy: 0.7873\n",
      "Epoch 13/99\n",
      "862/862 [==============================] - 1s 813us/step - loss: 0.4158 - accuracy: 0.7866\n",
      "Epoch 14/99\n",
      "862/862 [==============================] - 1s 807us/step - loss: 0.4151 - accuracy: 0.7898\n",
      "Epoch 15/99\n",
      "862/862 [==============================] - 1s 807us/step - loss: 0.4128 - accuracy: 0.7889\n",
      "Epoch 16/99\n",
      "862/862 [==============================] - 1s 815us/step - loss: 0.4119 - accuracy: 0.7926\n",
      "Epoch 17/99\n",
      "862/862 [==============================] - 1s 801us/step - loss: 0.4110 - accuracy: 0.7896\n",
      "Epoch 18/99\n",
      "862/862 [==============================] - 1s 838us/step - loss: 0.4090 - accuracy: 0.7910\n",
      "Epoch 19/99\n",
      "862/862 [==============================] - 1s 892us/step - loss: 0.4056 - accuracy: 0.7960\n",
      "Epoch 20/99\n",
      "862/862 [==============================] - 1s 859us/step - loss: 0.4048 - accuracy: 0.7948\n",
      "Epoch 21/99\n",
      "862/862 [==============================] - 1s 889us/step - loss: 0.4026 - accuracy: 0.7976\n",
      "Epoch 22/99\n",
      "862/862 [==============================] - 1s 853us/step - loss: 0.4026 - accuracy: 0.7981\n",
      "Epoch 23/99\n",
      "862/862 [==============================] - 1s 831us/step - loss: 0.3993 - accuracy: 0.7990\n",
      "Epoch 24/99\n",
      "194/862 [=====>........................] - ETA: 0s - loss: 0.3976 - accuracy: 0.7940"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_272\\3961673803.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincome_attributes_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincome_target_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1683\u001b[0m                         ):\n\u001b[0;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    924\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    141\u001b[0m       (concrete_function,\n\u001b[0;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1756\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.fit(income_attributes_train, income_target_train, epochs = 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "36671c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862/862 [==============================] - 1s 654us/step - loss: 0.3933 - accuracy: 0.8068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3933012783527374, 0.806828498840332]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(income_attributes_train, income_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6ace6010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 712us/step - loss: 0.3985 - accuracy: 0.8004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39848995208740234, 0.8004000186920166]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.evaluate(income_attributes_test, income_target_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
